\documentclass{article}
\usepackage[margin=1.0in]{geometry} % To set margins
\usepackage{amsmath}  % This allows me to use the align functionality.
                      % If you find yourself trying to replicate
                      % something you found online, ensure you're
                      % loading the necessary packages!
\usepackage{amsfonts} % Math font
\usepackage{fancyvrb}
\usepackage{hyperref} % For including hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\usepackage{float}    % For telling R where to put a table/figure
\usepackage{natbib}        %For the bibliography
\bibliographystyle{apalike}%For the bibliography

\begin{document}
<<echo=F, message=F, warning=F>>=
library(tidyverse)
library(VGAM)
library(xtable)
@

\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item A group of researchers is running an experiment over the course of 30 months, 
with a single observation collected at the end of each month. Let $X_1, ..., X_{30}$
denote the observations for each month. From prior studies, the researchers know that
\[X_i \sim f_X(x),\]
but the mean $\mu_X$ is unknown, and they wish to conduct the following test
\begin{align*}
H_0&: \mu_X = 0\\
H_a&: \mu_X > 0.
\end{align*}
At month $k$, they have accumulated data $X_1, ..., X_k$ and they have the 
$t$-statistic
\[T_k = \frac{\bar{X} - 0}{S_k/\sqrt{n}}.\]
The initial plan was to test the hypotheses after all data was collected (at the 
end of month 30), at level $\alpha=0.05$. However, conducting the experiment is 
expensive, so the researchers want to ``peek" at the data at the end of month 20 
to see if they can stop it early. That is, the researchers propose to check 
whether $t_{20}$ provides statistically discernible support for the alternative. 
If it does, they will stop the experiment early and report support for the 
researcher's alternative hypothesis. If it does not, they will continue to month 
30 and test whether $t_{30}$ provides statistically discernible support for the
alternative.

\begin{enumerate}
  \item What values of $t_{20}$ provide statistically discernible support for the
  alternative hypothesis?
  <<message=F, warning=F>>=
    # part A 
alpha <- 0.05
sample.sizeA <- 20
(hA.support20 = qt(p = 1-alpha, df = sample.sizeA-1))
    @
\textbf{Solution:} Any value for $t_{20} \geq 1.729$ provides statistically discernible support for the alternative hypothesis.
  \item What values of $t_{30}$ provide statistically discernible support for the
  alternative hypothesis?
  <<message = F, warning = F>>=
# part B
alpha <- 0.05
sample.sizeB <- 30
(hA.support30 = qt(p = 1-alpha, df = sample.sizeB-1))
@
\textbf{Solution:} Any value for $t_{30} \geq 1.699$ provides statistically discernible support for the alternative hypothesis.
  \item Suppose $f_X(x)$ is a Laplace distribution with $a=0$ and $b=4.0$.
  Conduct a simulation study to assess the Type I error rate of this approach.\\
  \textbf{Note:} You can use the \texttt{rlaplace()} function from the \texttt{VGAM}
  package for \texttt{R} \citep{VGAM}.
  <<message = F, warning = F>>=
# part C 
# simulation study 
mu0 <- 0
num.sims <- 10000
a <- 0
b <- 4.0

# errors
type1error.n20.peek <- 0
type1error.n30.peek <- 0
type1error.n30.final <- 0

for(i in 1:num.sims){
  # sims for n = 20 peek, n = 30
  curr.sim30 <- rlaplace(n=sample.sizeB, location = a, scale = b)
  curr.sim20 <- curr.sim30[1:20]
  
  # t test for n = 20 peek
  n20.test <- t.test(x = curr.sim20, mu = mu0, alternative = "greater")
  n20.t <- n20.test$statistic
  
  # t test for n = 30
  n30.test <- t.test(x = curr.sim30, mu = mu0, alternative = "greater")
  n30.t <- n30.test$statistic
  
  # if hA is supported with n = 20
  # if not continue on and see if hA is supported with n = 30
  if (n20.t >= hA.support20){
    type1error.n20.peek <- type1error.n20.peek + 1
  }
  
  # situation where researchers do not peek the data
  else if(n30.t >= hA.support30){
    type1error.n30.peek <- type1error.n30.peek + 1
  }

  if (n30.t >= hA.support30){
    type1error.n30.final <- type1error.n30.final + 1
  }
}


(e.rate.final <- type1error.n30.final/num.sims)

(e.rate.peek <- (type1error.n20.peek + type1error.n30.peek)
                /num.sims)
# the final error rate may differ each time, due to the randomness of rlaplace()
@
\textbf{Solution:} When using the researchers' approach of ``peeking" at the data after $20$ months, the Type I error rate is \Sexpr{e.rate.peek}. However, when just continuing through the $30$ months, the Type I error rate is \Sexpr{e.rate.final}. As shown, the Type I error rate is discernibly higher when using the researchers' approach, above the accepted $\alpha = 0.05$, compared to the Type I error rate after waiting $30$ months.
\item \textbf{Optional Challenge:} Can you find a value of $\alpha<0.05$ that yields a 
  Type I error rate of 0.05?
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Perform a simulation study to assess the robustness of the $T$ test. 
  Specifically, generate samples of size $n=15$ from the Beta(10,2), Beta(2,10), 
  and Beta(10,10) distributions and conduct the following hypothesis tests against 
  the actual mean for each case (e.g., $\frac{10}{10+2}$, $\frac{2}{10+2}$, and 
  $\frac{10}{10+10}$). 
  <<warning = F, message = F>>=
# Problem 2
# set.seed() so results reproducible (can use xtable)
set.seed(123456)
betatype1.errors <- function(a, b){
  num.sims <- 1000
  alpha <- a
  beta <- b
  pop.mean <- alpha/(alpha + beta)
  dist.skew <- (2*(beta-alpha)*sqrt(alpha+beta+1))/
               ((alpha + beta + 2)*sqrt(alpha*beta))
  sample.size2 <- 15
  
  # errors
  righttail.errors <- 0 
  lefttail.errors <- 0
  twotail.errors <- 0
  
  for(i in 1:num.sims){
    # sims using rbeta, n = 15
    curr.sim <- rbeta(n=sample.size2, shape1 = alpha, shape2 = beta)
    
    # t test for right tail 
    t.right <- t.test(x=curr.sim, mu = pop.mean, alternative = "greater")
    right.pval <- t.right$p.value
    # t test for left tail 
    t.left <- t.test(x=curr.sim, mu = pop.mean, alternative = "less")
    left.pval <- t.left$p.value
    # t test for two tailed
    t.twotail <- t.test(x=curr.sim, mu = pop.mean, alternative = "two.sided")
    twotail.pval <- t.twotail$p.value
    
    # count errors
    if (right.pval < 0.05){
      righttail.errors <- righttail.errors + 1
    }
    if (left.pval < 0.05){
      lefttail.errors <- lefttail.errors + 1
    }
    if(twotail.pval < 0.05){
      twotail.errors <- twotail.errors + 1
    }
  }
  
  # find proportion
  error.left <- lefttail.errors/num.sims
  error.right <- righttail.errors/num.sims
  error.twotail <- twotail.errors/num.sims
  
  tibble(type = c("left tailed", "right tailed", "two tailed", "skewness"),
         errors = c(error.left, error.right, error.twotail, dist.skew)) |>
    pivot_wider(names_from = type, values_from = errors)
}

errors.data <- tibble(bind_rows(betatype1.errors(a = 10, b = 2),
betatype1.errors(a = 2, b = 10),
betatype1.errors(a = 10, b = 10)))

# consolidate data 
(errors.table <- tibble(distribution = c("Beta(10,2)", "Beta(2,10)", 
                                        "Beta(10,10)"), errors.data))

xtable(errors.table)
@
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 distribution & left-tailed test & right-tailed test & two-tailed test & skewness \\ 
  \hline
Beta(10,2) & 0.030 & 0.075 & 0.051 & -0.921 \\ 
Beta(2,10) & 0.071 & 0.030 & 0.055 & 0.921 \\ 
Beta(10,10) & 0.051 & 0.048 & 0.044 & 0.000 \\ 
   \hline
\end{tabular}
\caption{Type I error proportions for different beta distributions, along with the skewness for each distribution.}
\label{table1}
\end{table}

  \begin{enumerate}
    \item What proportion of the time do we make an error of Type I for a
    left-tailed test? \\
    \textbf{Solution:} The Type I error proportions for a left-tailed test are \Sexpr{errors.data$`left tailed`[1]} for the Beta(10, 2) distribution, \Sexpr{errors.table$`left tailed`[2]} for the Beta(2, 10) distribution, and \Sexpr{errors.table$`left tailed`[3]} for the Beta(10, 10) distribution. 
    \item What proportion of the time do we make an error of Type I for a
    right-tailed test? \\
    \textbf{Solution:} The Type I error proportions for a right-tailed test are \Sexpr{errors.data$`right tailed`[1]} for the Beta(10, 2) distribution, \Sexpr{errors.table$`right tailed`[2]} for the Beta(2, 10) distribution, and \Sexpr{errors.table$`right tailed`[3]} for the Beta(10, 10) distribution. 
    \item What proportion of the time do we make an error of Type I for a
    two-tailed test? \\
    \textbf{Solution:} The Type I error proportions for a two-tailed test are \Sexpr{errors.data$`two tailed`[1]} for the Beta(10, 2) distribution, \Sexpr{errors.table$`two tailed`[2]} for the Beta(2, 10) distribution, and \Sexpr{errors.table$`two tailed`[3]} for the Beta(10, 10) distribution. 
    \item How does skewness of the underlying population distribution effect
    Type I error across the test types? \\
    \textbf{Solution:} The skewness and Type 1 error proportions of each distribution can be found in Table \ref{table1}. \\
The Beta(10, 2) distribution is left-skewed, increasing the proportion of Type 1 errors for the right-tailed test and decreasing the proportion of Type 1 errors for the left-tailed test. \\
The Beta(2, 10) distribution is right-skewed, increasing the proportion of Type 1 errors for the left-tailed test and decreasing the proportion of Type 1 errors for the right-tailed test. \\
The Beta(10, 10) distribution is symmetric, so the proportion of Type 1 errors for all tests is just about the same. 
  
  \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% End Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}
\bibliography{bibliography}
\end{document}
